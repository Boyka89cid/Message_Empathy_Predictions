{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/akashdevgun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether Cuda is Available: True\n"
     ]
    }
   ],
   "source": [
    "# Importing Main Libraries For Empathy Prediction Problem Set\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.current_device()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.backends.cudnn as cudnn\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "from data_embeddings import EmpathyDataLoading, DataProcessing\n",
    "from lstm_models import LSTM_fix_input, LSTM_var_input, LSTM_glove_vecs_input\n",
    "from training_testing_criterion import train, get_criterion_optimizer_scheduler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)\n",
    "\n",
    "# Model training using GPU in CUDA Environment\n",
    "print(\"Whether Cuda is Available: {}\".format(torch.cuda.is_available()))\n",
    "\n",
    "# File Names\n",
    "label_message_file = \"/media/HDD_2TB.1/Empathy-Predictions/labeled_messages.csv\"\n",
    "empathies = \"/media/HDD_2TB.1/Empathy-Predictions/empathies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that calls to train different types of LSTMs\n",
    "def training_LSTMs(model, epochs, learning_rate, loss_weights, device, train_queue, valid_queue):\n",
    "    model = model.to(device)\n",
    "    criterion, optimizer, scheduler = get_criterion_optimizer_scheduler(model, epochs, learning_rate,\n",
    "                                                                        loss_weights, device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        scheduler.step()\n",
    "        train(model, device, train_queue, valid_queue, optimizer, epoch, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Method\n",
    "def main():\n",
    "    # Object 'Data' is created by Class Named -> 'DataProcessing'. file names are parameters\n",
    "    data_obj = DataProcessing(label_message_file, empathies)\n",
    "\n",
    "    # Method describes messages lengths, number of words in Corpus \n",
    "    data_obj.describe_counts()\n",
    "\n",
    "    # Method for MultiLabel Encoding, weighted label weights for label data imbalance\n",
    "    output_size, loss_weights = data_obj.label_binarizer_get_weights()\n",
    "\n",
    "    # Get X and Y\n",
    "    X = data_obj.get_X_data()\n",
    "    y = data_obj.get_Y_data()\n",
    "    print('\\n')\n",
    "\n",
    "    # Training and Testing Split\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Baseline Classifier using Support Vector Classifier to calculate Accuracy and Area Under Curve \n",
    "    print(\"*** Baseline AUC Scores ***\")\n",
    "    acc_svm, roc_svm = data_obj.modelling(\"SVC\", X_train, X_valid, y_train, y_valid)\n",
    "    print(\"SVM Modelling --> Validation Acc. : %.3f, Validation AUC Score : %.3f\" % (acc_svm, roc_svm))\n",
    "    acc_RF, roc_RF = data_obj.modelling(\"RandomForest\", X_train, X_valid, y_train, y_valid)\n",
    "    print(\"Random Forest Modelling --> Validation Acc. : %.3f, Validation AUC Score : %.3f\" % (acc_RF, roc_RF))\n",
    "    print(\"** Statistical Method performed better then Baseline **\")\n",
    "\n",
    "    # 'EmpathyDataLoading' Class for training and validation data to load while run time\n",
    "    train_ds = EmpathyDataLoading(X_train, y_train)\n",
    "    valid_ds = EmpathyDataLoading(X_valid, y_valid)\n",
    "\n",
    "    vocab_size = len(data_obj.words)\n",
    "    epochs = 1001\n",
    "    batch_size = 1000\n",
    "    learning_rate = 0.3\n",
    "\n",
    "    # Data Loader for train and test\n",
    "    train_queue = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_queue = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # CUDA Environment Conf.\n",
    "    torch.cuda.set_device(0)\n",
    "    cudnn.benchmark = True\n",
    "    torch.manual_seed(1)\n",
    "    cudnn.enabled = True\n",
    "    torch.cuda.manual_seed(1)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # LSTMs models with fixed Input length, var Input length, using Stanford Glove Vec Representations\n",
    "    print('\\n')\n",
    "    print('-----------LSTMs Fixed Input Length--------------')\n",
    "    model_fix_len = LSTM_fix_input(vocab_size, 48, 96, output_size)\n",
    "    training_LSTMs(model_fix_len, epochs, learning_rate, loss_weights, device, train_queue, valid_queue)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-----------LSTMs Var Input Length--------------')\n",
    "    model_var_len = LSTM_var_input(vocab_size, 48, 96, output_size)\n",
    "    training_LSTMs(model_var_len, epochs, learning_rate, loss_weights, device, train_queue, valid_queue)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-----------LSTMs with Glove Representations--------------')\n",
    "    word_vecs = data_obj.load_glove_vectors()\n",
    "    pretrained_weights, vocab, vocab2index = data_obj.get_emb_matrix(word_vecs)\n",
    "    model_glove = LSTM_glove_vecs_input(vocab_size, 50, 96, pretrained_weights, output_size)\n",
    "    training_LSTMs(model_glove, epochs, learning_rate, loss_weights, device, train_queue, valid_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape is: (3562, 4)\n",
      "Intial 10 Rows :\n",
      "   num_seen          message       empathy ignore\n",
      "0      2884            tired         tired    NaN\n",
      "1       253        exhausted         tired    NaN\n",
      "2        61          drained         tired    NaN\n",
      "3        31  tired but happy  tired, happy    NaN\n",
      "4        30         im tired         tired    NaN\n",
      "5        29       very tired         tired    NaN\n",
      "6        28      a bit tired         tired    NaN\n",
      "7        28     i feel tired         tired    NaN\n",
      "8        25   tired but good   tired, good    NaN\n",
      "9        24         worn out         tired    NaN\n",
      "\n",
      "\n",
      "Number of words in Corpus: 2114\n",
      "Message Avg Length : 5.123526108927569, Message Max Length : 121\n",
      "Number of Empathies: 62, Output Shape is: (3562, 62)\n",
      "\n",
      "\n",
      "First 10 Columns of Data After Data Preprocessing and MultiLabel Encoding:\n",
      "   num_seen          message       empathy  message_length  \\\n",
      "0      2884            tired         tired               1   \n",
      "1       253        exhausted         tired               1   \n",
      "2        61          drained         tired               1   \n",
      "3        31  tired but happy  tired, happy               3   \n",
      "4        30       i am tired         tired               3   \n",
      "5        29       very tired         tired               2   \n",
      "6        28      a bit tired         tired               3   \n",
      "7        28     i feel tired         tired               3   \n",
      "8        25   tired but good   tired, good               3   \n",
      "9        24         worn out         tired               2   \n",
      "\n",
      "                                             encoded       y_encoded  \\\n",
      "0  [[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "1  [[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "2  [[4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "3  [[2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  [tired, happy]   \n",
      "4  [[7, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "5  [[9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...         [tired]   \n",
      "6  [[10, 11, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         [tired]   \n",
      "7  [[7, 12, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...         [tired]   \n",
      "8  [[2, 5, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   [tired, good]   \n",
      "9  [[14, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         [tired]   \n",
      "\n",
      "                                       y_encoded_int  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Baseline AUC Scores ***\n",
      "SVM Modelling --> Validation Acc. : 0.976, Validation AUC Score : 0.584\n",
      "Random Forest Modelling --> Validation Acc. : 0.900, Validation AUC Score : 0.698\n",
      "** Statistical Method performed better then Baseline **\n",
      "\n",
      "\n",
      "-----------LSTMs Fixed Input Length--------------\n",
      "Epoch: 1, Train loss: 0.676, Val loss: 0.668, Val Acc: 0.621, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.476, Val Precision Weighted : 0.955\n",
      "Epoch: 101, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.636, Val AUC_ROC Weighted : 0.636, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 201, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.678, Val AUC_ROC Weighted : 0.678, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 301, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.697, Val AUC_ROC Weighted : 0.697, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 401, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.705, Val AUC_ROC Weighted : 0.705, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 501, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.708, Val AUC_ROC Weighted : 0.708, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 601, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.710, Val AUC_ROC Weighted : 0.710, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 701, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.712, Val AUC_ROC Weighted : 0.712, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 801, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.712, Val AUC_ROC Weighted : 0.712, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 901, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.713, Val AUC_ROC Weighted : 0.713, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 1001, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.713, Val AUC_ROC Weighted : 0.713, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "\n",
      "\n",
      "-----------LSTMs Var Input Length--------------\n",
      "Epoch: 1, Train loss: 0.673, Val loss: 0.666, Val Acc: 0.614, Val AUC_ROC Macro: 0.477, Val AUC_ROC Weighted : 0.477, Val Recall Macro: 0.486, Val Precision Weighted : 0.956\n",
      "Epoch: 101, Train loss: 0.011, Val loss: 0.011, Val Acc: 0.978, Val AUC_ROC Macro: 0.479, Val AUC_ROC Weighted : 0.479, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 201, Train loss: 0.009, Val loss: 0.010, Val Acc: 0.978, Val AUC_ROC Macro: 0.479, Val AUC_ROC Weighted : 0.479, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 301, Train loss: 0.009, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.481, Val AUC_ROC Weighted : 0.481, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 401, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.482, Val AUC_ROC Weighted : 0.482, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 501, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.484, Val AUC_ROC Weighted : 0.484, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 601, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.486, Val AUC_ROC Weighted : 0.486, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 701, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.487, Val AUC_ROC Weighted : 0.487, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 801, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 901, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 1001, Train loss: 0.008, Val loss: 0.009, Val Acc: 0.978, Val AUC_ROC Macro: 0.488, Val AUC_ROC Weighted : 0.488, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "\n",
      "\n",
      "-----------LSTMs with Glove Representations--------------\n",
      "Epoch: 1, Train loss: 0.684, Val loss: 0.677, Val Acc: 0.467, Val AUC_ROC Macro: 0.509, Val AUC_ROC Weighted : 0.509, Val Recall Macro: 0.473, Val Precision Weighted : 0.955\n",
      "Epoch: 101, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.615, Val AUC_ROC Weighted : 0.615, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 201, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.657, Val AUC_ROC Weighted : 0.657, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 301, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.687, Val AUC_ROC Weighted : 0.687, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 401, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.700, Val AUC_ROC Weighted : 0.700, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 501, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.706, Val AUC_ROC Weighted : 0.706, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 601, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.707, Val AUC_ROC Weighted : 0.707, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 701, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.708, Val AUC_ROC Weighted : 0.708, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 801, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.708, Val AUC_ROC Weighted : 0.708, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 901, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.708, Val AUC_ROC Weighted : 0.708, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n",
      "Epoch: 1001, Train loss: 0.002, Val loss: 0.002, Val Acc: 0.978, Val AUC_ROC Macro: 0.708, Val AUC_ROC Weighted : 0.708, Val Recall Macro: 0.500, Val Precision Weighted : 0.957\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
